{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from gensim.models import word2vec\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import plotly as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/nsfw_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>numberOfComments</th>\n",
       "      <th>over18</th>\n",
       "      <th>upVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt happen like year ago feel like fever dre...</td>\n",
       "      <td>95</td>\n",
       "      <td>False</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f alway say 's ugli old stuff like nobodi like...</td>\n",
       "      <td>244</td>\n",
       "      <td>True</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hi im f dental assist clean accident get prick...</td>\n",
       "      <td>265</td>\n",
       "      <td>False</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context wife f parent beauti toddler ym f rent...</td>\n",
       "      <td>138</td>\n",
       "      <td>True</td>\n",
       "      <td>1372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yesterday 's fuckup spill go crazi f frequent ...</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  numberOfComments  \\\n",
       "0  didnt happen like year ago feel like fever dre...                95   \n",
       "1  f alway say 's ugli old stuff like nobodi like...               244   \n",
       "2  hi im f dental assist clean accident get prick...               265   \n",
       "3  context wife f parent beauti toddler ym f rent...               138   \n",
       "4  yesterday 's fuckup spill go crazi f frequent ...                31   \n",
       "\n",
       "   over18  upVotes  \n",
       "0   False      392  \n",
       "1    True      867  \n",
       "2   False      920  \n",
       "3    True     1372  \n",
       "4   False       45  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body                0\n",
       "numberOfComments    0\n",
       "over18              0\n",
       "upVotes             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test subsets\n",
    "split = StratifiedShuffleSplit(n_splits=5, test_size=0.25)\n",
    "\n",
    "for train_index, test_index in split.split(df,\n",
    "                                           df[\"over18\"]): \n",
    "    df_train = df.reindex(train_index)\n",
    "    df_test = df.reindex(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=[\"numberOfComments\", \"upVotes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>over18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>ive see guy almost month like love first sight...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>run home gym realli close hous woman stand aro...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>get home univers hungri alreadi thought want m...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>ampxb hi plea vote favorit post decemb post ac...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>autisticdiagnos adult social cue import tend o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>day ago around walk back home grab smoke live ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>obligatori obligatori famili want uncl christm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>earlier post realiz want abstain sex bf month ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>ill prefac say good day overal last straw ish ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>actual happend yesterday littel backgraound im...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  over18\n",
       "578  ive see guy almost month like love first sight...   False\n",
       "264  run home gym realli close hous woman stand aro...   False\n",
       "359  get home univers hungri alreadi thought want m...   False\n",
       "305  ampxb hi plea vote favorit post decemb post ac...   False\n",
       "299  autisticdiagnos adult social cue import tend o...   False\n",
       "..                                                 ...     ...\n",
       "303  day ago around walk back home grab smoke live ...    True\n",
       "458  obligatori obligatori famili want uncl christm...   False\n",
       "826  earlier post realiz want abstain sex bf month ...    True\n",
       "300  ill prefac say good day overal last straw ish ...   False\n",
       "879  actual happend yesterday littel backgraound im...    True\n",
       "\n",
       "[665 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665, 222)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.822556\n",
       "True     0.177444\n",
       "Name: over18, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"over18\"].value_counts()/len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.81982\n",
       "True     0.18018\n",
       "Name: over18, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"over18\"].value_counts()/len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_params = [\n",
    "    {'name': 'SVC', 'classifier': SVC(), 'param_grid': {'classifier__C': [0.1, 1, 10], 'classifier__kernel': ['linear', 'rbf']}},\n",
    "    {'name': 'Logistic Regression', 'classifier': LogisticRegression(class_weight='balanced'), 'param_grid': {'classifier__C': [1], 'classifier__solver': ['saga']}},\n",
    "    {'name': 'Logistic Regression_L2', 'classifier': LogisticRegression(class_weight='balanced'), 'param_grid': {'classifier__C': [1], 'classifier__penalty':['l2'], 'classifier__solver': ['saga']}},\n",
    "    {'name': 'Random Forest', 'classifier': RandomForestClassifier(class_weight='balanced'), 'param_grid': {'classifier__n_estimators': [50, 100], 'classifier__max_depth': [5, 10, 20]}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "SVC - Best F1 Score on Validation: 0.3327400588026775\n",
      "\n",
      "Confusion Matrix (SVC):\n",
      " [[170  12]\n",
      " [ 30  10]]\n",
      "SVC - F1 Score on Test: 0.3225806451612903\n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Logistic Regression - Best F1 Score on Validation: 0.4540926916221034\n",
      "\n",
      "Confusion Matrix (Logistic Regression):\n",
      " [[154  28]\n",
      " [ 28  12]]\n",
      "Logistic Regression - F1 Score on Test: 0.3\n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Logistic Regression_L2 - Best F1 Score on Validation: 0.4540926916221034\n",
      "\n",
      "Confusion Matrix (Logistic Regression_L2):\n",
      " [[154  28]\n",
      " [ 28  12]]\n",
      "Logistic Regression_L2 - F1 Score on Test: 0.3\n",
      "\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Random Forest - Best F1 Score on Validation: 0.18933735897028442\n",
      "\n",
      "Confusion Matrix (Random Forest):\n",
      " [[179   3]\n",
      " [ 38   2]]\n",
      "Random Forest - F1 Score on Test: 0.0888888888888889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_params in models_params:\n",
    "    random.seed(20)\n",
    "    # Create a pipeline for TF-IDF Vectorization and model training\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', model_params['classifier'])\n",
    "    ])\n",
    "\n",
    "    # Combine parameter grid from models_params with TF-IDF specific parameters\n",
    "    param_grid = {\n",
    "        'tfidf__max_features': [1000, 5000, None],\n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "        **model_params['param_grid']\n",
    "    }\n",
    "\n",
    "    # Perform grid search with F1 score as the scoring metric\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', verbose=1)\n",
    "    grid_search.fit(df_train['body'], df_train[\"over18\"])\n",
    "\n",
    "    # Get best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predict on test data\n",
    "    predictions = best_model.predict(df_test['body'])\n",
    "    conf_matrix = confusion_matrix(df_test[\"over18\"], predictions)\n",
    "    \n",
    "    # Print F1 score on validation (grid_search) point\n",
    "    print(f\"{model_params['name']} - Best F1 Score on Validation: {grid_search.best_score_}\")\n",
    "\n",
    "    # Print confusion matrix\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f\"Confusion Matrix: {model_params['name']}\" )\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate F1 score on test data\n",
    "    f1_test = f1_score(df_test[\"over18\"], predictions)\n",
    "    print(f\"{model_params['name']} - F1 Score on Test: {f1_test}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sentences\n",
    "tokenized_train_sentences = [sentence.split() for sentence in df_train['body']]\n",
    "tokenized_test_sentences = [sentence.split() for sentence in df_test['body']]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = word2vec.Word2Vec(sentences=tokenized_train_sentences, vector_size=100, window=5, min_count=1, workers=10)\n",
    "\n",
    "# Transform tokenized sentences using Word2Vec\n",
    "X_train_embedded = np.array([np.mean([word2vec_model.wv[word] for word in sentence if word in word2vec_model.wv] or [np.zeros(word2vec_model.vector_size)], axis=0) for sentence in tokenized_train_sentences])\n",
    "X_test_embedded = np.array([np.mean([word2vec_model.wv[word] for word in sentence if word in word2vec_model.wv] or [np.zeros(word2vec_model.vector_size)], axis=0) for sentence in tokenized_test_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "SVC - Best F1 Score on Validation: 0.0\n",
      "\n",
      "Confusion Matrix (SVC):\n",
      " [[182   0]\n",
      " [ 40   0]]\n",
      "SVC - F1 Score on Test: 0.0\n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Logistic Regression - Best F1 Score on Validation: 0.3200333274505549\n",
      "\n",
      "Confusion Matrix (Logistic Regression):\n",
      " [[117  65]\n",
      " [ 24  16]]\n",
      "Logistic Regression - F1 Score on Test: 0.2644628099173554\n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Logistic Regression_L2 - Best F1 Score on Validation: 0.3193012295324583\n",
      "\n",
      "Confusion Matrix (Logistic Regression_L2):\n",
      " [[117  65]\n",
      " [ 24  16]]\n",
      "Logistic Regression_L2 - F1 Score on Test: 0.2644628099173554\n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Random Forest - Best F1 Score on Validation: 0.04444444444444444\n",
      "\n",
      "Confusion Matrix (Random Forest):\n",
      " [[181   1]\n",
      " [ 37   3]]\n",
      "Random Forest - F1 Score on Test: 0.13636363636363635\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_params in models_params:\n",
    "    # Create a pipeline for clustering and model training\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Standardize the features\n",
    "        ('pca', PCA(n_components=100)),  # Principal Component Analysis for dimensionality reduction\n",
    "        ('classifier', model_params['classifier'])\n",
    "    ])\n",
    "\n",
    "    # Combine parameter grid from models_params with embedding specific parameters\n",
    "    param_grid = {\n",
    "        **model_params['param_grid']\n",
    "    }\n",
    "\n",
    "    # Perform grid search with F1 score as the scoring metric\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', verbose=1)\n",
    "    grid_search.fit(X_train_embedded, df_train[\"over18\"])\n",
    "\n",
    "    # Get best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predict on test data\n",
    "    predictions = best_model.predict(X_test_embedded)\n",
    "    conf_matrix = confusion_matrix(df_test[\"over18\"], predictions)\n",
    "    \n",
    "    # Print F1 score on validation (grid_search) point\n",
    "    print(f\"{model_params['name']} - Best F1 Score on Validation: {grid_search.best_score_}\")\n",
    "\n",
    "    # Print confusion matrix\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f\"Confusion Matrix: {model_params['name']}\" )\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate F1 score on test data\n",
    "    f1_test = f1_score(df_test[\"over18\"], predictions)\n",
    "    print(f\"{model_params['name']} - F1 Score on Test: {f1_test}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
